{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Feature Selection Tutorial\n",
    "Welcome to the Ensemble Feature Selection Tutorial! In this tutorial, we will guide you through the straightforward process of using a multi-objective optimization approach to select features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example dataset\n",
    "\n",
    "To illustrate our method we will use the wine dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  target  \n",
      "0                          3.92   1065.0       0  \n",
      "1                          3.40   1050.0       0  \n",
      "2                          3.17   1185.0       0  \n",
      "3                          3.45   1480.0       0  \n",
      "4                          2.93    735.0       0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "\n",
    "# Load Wine dataset\n",
    "wine_data = load_wine()\n",
    "wine_df = pd.DataFrame(data= wine_data.data, columns= wine_data.feature_names)\n",
    "wine_df['target'] = wine_data.target\n",
    "print(wine_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFS pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the Ensemble Feature Selection Pipeline, you need to define several key parameters. For detailed information on each parameter, please refer to the documentation here or consult the Getting Started tutorial here for an in-depth exploration.\n",
    "\n",
    "Now, we will outline a basic configuration of parameters and provide a simple demonstration of how to execute the pipeline to select features effectively.\n",
    "\n",
    "Let's first import the main class and define the necessary parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moosefs import FeatureSelectionPipeline\n",
    "\n",
    "fs_methods = [\n",
    "    \"f_statistic_selector\",\n",
    "    \"random_forest_selector\",\n",
    "    \"mutual_info_selector\",\n",
    "    \"xgboost_selector\",\n",
    "    \"svm_selector\"\n",
    "]\n",
    "merging_strategy = \"union_of_intersections_merger\"\n",
    "num_repeats = 5\n",
    "task = \"classification\"\n",
    "num_features_to_select = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the necessary parameters, we can proceed to initialize a pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = FeatureSelectionPipeline(\n",
    "    data=wine_df,\n",
    "    fs_methods=fs_methods,\n",
    "    merging_strategy=merging_strategy,\n",
    "    num_repeats=num_repeats,\n",
    "    task=task,\n",
    "    num_features_to_select=num_features_to_select\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can directly execute the pipeline using the .run() method or by calling the pipeline object itself—it's that simple! This execution will return a list of the selected features, along with the best repeat and the group name associated with those selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipeline Progress: 100%|██████████| 5/5 [02:25<00:00, 29.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the Feature Selection Pipeline:\n",
      "\n",
      "Selected Features:\n",
      "1. hue\n",
      "2. proline\n",
      "3. malic_acid\n",
      "4. od280/od315_of_diluted_wines\n",
      "5. alcohol\n",
      "6. flavanoids\n",
      "7. color_intensity\n",
      "\n",
      "Best Group Name: ('FStatistic', 'RandomForest', 'MutualInfo', 'XGBoost', 'SVM')\n",
      "Best Repeat Index: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of running the pipeline\n",
    "selected_features, best_repeat_index, best_group_name = pipeline.run()\n",
    "print(\"Results of the Feature Selection Pipeline:\\n\")\n",
    "print(\"Selected Features:\")\n",
    "for index, feature in enumerate(selected_features, start=1):\n",
    "    print(f\"{index}. {feature}\")\n",
    "\n",
    "print(\"\\nBest Group Name:\", best_group_name)\n",
    "print(\"Best Repeat Index:\", best_repeat_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Thank you for following this tutorial on ensemble feature selection. Utilize these techniques to improve the robustness and performance of your feature selection tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
