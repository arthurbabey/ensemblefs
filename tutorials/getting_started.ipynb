{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c826e64",
   "metadata": {},
   "source": [
    "# Getting Started with Ensemble Feature Selection\n",
    "\n",
    "Welcome to the Ensemble Feature Selection library! In this notebook, we will provide you with a guided tour\n",
    "of the library's features and functionalities. You will learn how to set up the pipeline, define key parameters,\n",
    "and utilize various methods for effective feature selection through a multi-objective optimization approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd5518",
   "metadata": {},
   "source": [
    "## Project Structure Overview\n",
    "The project structure is organized as follows:\n",
    "- **core**: Contains core functionality including data processing and metrics calculation.\n",
    "- **utils**: Some utility functions.\n",
    "- **feature_selectors**: Includes various feature selection methods like f_statistic, mutual_info, and others.\n",
    "- **merging_strategies**: Houses methods for merging feature selection results.\n",
    "- **feature_selection_pipeline**: Main class that can exectute the whole pipeline using the .run method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9419dfc8",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "To set up your environment, you need to the efs library, you can simply do pip install ensemblefeatureselection, or you can install it from root and do pip install . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ensemblefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb11475",
   "metadata": {},
   "source": [
    "## The feature_selection_pipeline Class\n",
    "\n",
    "The feature_selection_pipeline class is the core component of our project. It orchestrates the feature selection process based on the configurations you provide.\n",
    "\n",
    "Basic Usage\n",
    "To use the pipeline, you simply need to define the necessary parameters and execute the .run() method. All the underlying logic is encapsulated within this function. For a deeper understanding of the pipeline's operations, please refer to the documentation.\n",
    "\n",
    "How It Works\n",
    "1. Group Creation: The pipeline creates ùëÅ groups of the feature selection methods you have selected.\n",
    "2. Feature Selection: Based on the merging strategies, the desired number of features to select, and other parameters, it will perform feature selection for all these groups over ùëÄM repeats.\n",
    "3. Metrics: The pipeline compute performance and stability metrics for each group on the different fold of data.\n",
    "4. Multi-Objective Optimization: Utilizing a Pareto-based method, it returns the selected features.\n",
    "This class provides a powerful and flexible approach to feature selection, enabling you to harness the strengths of multiple methods in a cohesive framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b4de2d",
   "metadata": {},
   "source": [
    "## Pipeline Configuration Parameters\n",
    "\n",
    "Configuration parameters play a crucial role in customizing the behavior of the pipeline. \n",
    "\n",
    "Here are the necessary ones : \n",
    "\n",
    "- **data**: Dataset (pandas.DataFrame)\n",
    "- **fs_methods**: List of feature selection methods.\n",
    "- **merging_strategy**: Strategy to merge results from different selectors.\n",
    "- **num_repeats, num_features_to_select, task**: Other important parameters to define the behavior of the pipeline.\n",
    "\n",
    "And the rest of the parameters : \n",
    "\n",
    "- min_group_size: Minimum size (number of methods) for each groups (each ensemble)\n",
    "- random_state=: Random seed,\n",
    "- n_jobs: Set the number of jobs for scikit-learn method that accept the parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256ad5e",
   "metadata": {},
   "source": [
    "## DataProcessor Module\n",
    "\n",
    "The `DataProcessor` module facilitates the transition from raw data to a well-structured pandas DataFrame suitable for use in the pipeline. With customizable parameters, it allows you to handle categorical variables, drop unnecessary columns, manage missing values, and normalize numerical features. By configuring the processor according to your dataset's needs, you ensure optimal performance of the feature selection pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd493a9",
   "metadata": {},
   "source": [
    "Example : \n",
    "\n",
    "```python\n",
    "\n",
    "from ensemblefs.core import DataProcessor\n",
    "\n",
    "dp = DataProcessor(\n",
    "    categorical_columns=['category1', 'category2'],\n",
    "    columns_to_drop=['unwanted_column'],\n",
    "    drop_missing_values=True,\n",
    "    merge_key='id',\n",
    "    normalize=True,\n",
    "    target_column='target'\n",
    ")\n",
    "\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "processed_data = dp.preprocess(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f70c9",
   "metadata": {},
   "source": [
    "## Pipeline Example\n",
    "\n",
    "To demonstrate the usage of the `FeatureSelectionPipeline`, we can set up the feature selection methods and configuration parameters as follows:\n",
    "\n",
    "```python\n",
    "from ensemblefs import FeatureSelectionPipeline\n",
    "\n",
    "# Define feature selection methods\n",
    "fs_methods = [\n",
    "    \"f_statistic_selector\",\n",
    "    \"random_forest_selector\",\n",
    "    \"mutual_info_selector\",\n",
    "]\n",
    "\n",
    "# Configuration parameters\n",
    "merging_strategy = \"union_of_intersections_merger\"\n",
    "num_repeats = 5\n",
    "metrics = [\"logloss\", \"f1_score\", \"accuracy\"]\n",
    "task = \"classification\"\n",
    "random_state = 2024\n",
    "num_features_to_select = 6\n",
    "n_jobs = 1\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = FeatureSelectionPipeline(\n",
    "    data=processed_data,\n",
    "    fs_methods=fs_methods,\n",
    "    merging_strategy=merging_strategy,\n",
    "    num_repeats=num_repeats,\n",
    "    num_features_to_select=num_features_to_select,\n",
    "    metrics=metrics,\n",
    "    task=task,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "# Run the pipeline\n",
    "results = pipeline.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26253a05",
   "metadata": {},
   "source": [
    "Instead of defining feature sections methods and merging strategy with string identifier you can also define class object from the respectives class and you can tune them with their parameters. For more information you can look at the advanced example tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27c3f7",
   "metadata": {},
   "source": [
    "## Pipeline with script and config file\n",
    "\n",
    "The example above demonstrates how to use the `FeatureSelectionPipeline` directly by configuring parameters in the script. However, you can also utilize a configuration file to streamline the process. We provide a `config.yml` template that allows you to define your parameters in a structured format.\n",
    "\n",
    "With a simple script, you can parse the configuration file and execute the ensemble feature selection pipeline, making it easy to define and adjust parameters without modifying the code directly. A template script, `main.py`, is included for this purpose.\n",
    "\n",
    "You can run the pipeline by executing the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "python main.py dataset.csv config.yml\n",
    "```\n",
    "\n",
    "Feel free to customize the script and configuration file as needed to suit your specific requirements!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0e6f8",
   "metadata": {},
   "source": [
    "## Extend the library \n",
    "\n",
    "You can easily extend the functionality of the FeatureSelectionPipeline by defining new merging strategies and feature selection classes. This flexibility allows you to tailor the pipeline to your specific needs and explore different approaches to feature selection. For detailed guidance on how to implement these customizations, please refer to the [documentation](https://arthurbabey.github.io/EnsembleFeatureSelection/) or the relevant tutorials provided."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
